{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3e47f7-8489-40c3-8780-c2dcb936ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|█████████████████████████████████████████████████████| 22615/22615 [15:58<00:00, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete and state saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Initialize and load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\datasets\\agri.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Generate embeddings\n",
    "question_embeddings = {}\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Generating Embeddings\"):\n",
    "    question_embeddings[row['question']] = get_embedding(row['question'])\n",
    "\n",
    "# Save embeddings and questions to disk\n",
    "save_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\Saved_state\\embeddings.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump((question_embeddings, data), f)\n",
    "\n",
    "print(\"Preprocessing complete and state saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b79345c-abc8-4ee7-9d29-dbf6ba1d762f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your agricultural question (type 'exit' to quit):  എന്താണ് വിള ഭ്രമണം\n",
      "Enter the language code (en, ml, te, kn, hi):  ml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is crop rotation\n",
      "Answer: Crop rotation is the practice of growing a series of different crops in the same area over several seasons\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your agricultural question (type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the chatbot.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from googletrans import Translator\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gtts import gTTS\n",
    "import playsound\n",
    "import pickle\n",
    "\n",
    "# Load saved embeddings and dataset\n",
    "load_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\Saved_state\\embeddings.pkl'\n",
    "with open(load_path, 'rb') as f:\n",
    "    question_embeddings, data = pickle.load(f)\n",
    "\n",
    "# Load the multilingual model for embedding generation\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Function to convert sentences to embeddings\n",
    "def get_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(1)\n",
    "    return embeddings\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def translate_to_english(text, src_lang):\n",
    "    if src_lang != 'en':\n",
    "        result = translator.translate(text, src='auto', dest='en')\n",
    "        return result.text\n",
    "    return text\n",
    "\n",
    "def find_closest_question(query, src_lang):\n",
    "    query_eng = translate_to_english(query, src_lang)\n",
    "    query_emb = get_embedding(query_eng)  # Correctly generating embeddings\n",
    "    similarities = {q: cosine_similarity(query_emb, emb).flatten()[0] for q, emb in question_embeddings.items()}\n",
    "    closest_question = max(similarities, key=similarities.get)\n",
    "    return closest_question, data[data['question'] == closest_question]['answers'].iloc[0]\n",
    "\n",
    "def text_to_speech(text, lang):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    filename = 'D:/YEAR 4/SEM 7/NLP/LAB/PROJECT/codesspeech.mp3'\n",
    "    tts.save(filename)\n",
    "    playsound.playsound(filename)\n",
    "\n",
    "def chatbot_query():\n",
    "    while True:\n",
    "        question = input(\"Enter your agricultural question (type 'exit' to quit): \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting the chatbot.\")\n",
    "            break\n",
    "        src_lang = input(\"Enter the language code (en, ml, te, kn, hi): \")\n",
    "        closest_question, answer = find_closest_question(question, src_lang)\n",
    "        print(\"Question:\", closest_question)\n",
    "        print(\"Answer:\", answer)\n",
    "        text_to_speech(answer, src_lang)\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_query()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9781a2f-9477-453e-bd31-60c1b3a405e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Language data is not available.\n",
      "Relevance scores are not logged.\n",
      "Insufficient data to generate report.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def load_interaction_logs(log_path):\n",
    "    \"\"\"\n",
    "    Load the chatbot interaction logs from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(log_path)\n",
    "\n",
    "def calculate_language_accuracy(log_df):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the language detection.\n",
    "    This function assumes that the correct languages are logged or that you have a way to verify the accuracy post hoc.\n",
    "    \"\"\"\n",
    "    # Assuming 'Detected Language' and 'Actual Language' columns exist\n",
    "    if 'Actual Language' in log_df.columns:\n",
    "        accuracy = accuracy_score(log_df['Actual Language'], log_df['Detected Language'])\n",
    "        return accuracy\n",
    "    else:\n",
    "        print(\"Actual Language data is not available.\")\n",
    "        return None\n",
    "\n",
    "def answer_relevance_metrics(log_df):\n",
    "    \"\"\"\n",
    "    Placeholder function to calculate metrics related to the relevance of answers.\n",
    "    This could involve manual tagging of data or automated feedback from users.\n",
    "    \"\"\"\n",
    "    if 'Relevance Score' in log_df.columns:\n",
    "        average_relevance = log_df['Relevance Score'].mean()\n",
    "        return average_relevance\n",
    "    else:\n",
    "        print(\"Relevance scores are not logged.\")\n",
    "        return None\n",
    "\n",
    "def print_classification_report(log_df):\n",
    "    \"\"\"\n",
    "    Print the classification report for language detection.\n",
    "    \"\"\"\n",
    "    if 'Actual Language' in log_df.columns:\n",
    "        print(classification_report(log_df['Actual Language'], log_df['Detected Language']))\n",
    "    else:\n",
    "        print(\"Insufficient data to generate report.\")\n",
    "\n",
    "def main():\n",
    "    log_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\conversation_logs.csv'\n",
    "    log_df = load_interaction_logs(log_path)\n",
    "    \n",
    "    # Calculate and print language detection accuracy\n",
    "    lang_accuracy = calculate_language_accuracy(log_df)\n",
    "    if lang_accuracy is not None:\n",
    "        print(f\"Language Detection Accuracy: {lang_accuracy:.2f}\")\n",
    "    \n",
    "    # Calculate and print answer relevance metrics\n",
    "    relevance = answer_relevance_metrics(log_df)\n",
    "    if relevance is not None:\n",
    "        print(f\"Average Relevance Score: {relevance:.2f}\")\n",
    "    \n",
    "    # Print classification report for language detection\n",
    "    print_classification_report(log_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1829f9be-1c72-4790-8c21-8ec7e01e008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Question           4 non-null      object\n",
      " 1   Answer             4 non-null      object\n",
      " 2   Source Language    4 non-null      object\n",
      " 3   Question Language  4 non-null      object\n",
      " 4   Timestamp          4 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 292.0+ bytes\n",
      "\n",
      "First 5 Rows:\n",
      "                   Question  \\\n",
      "0     what are fertilizers?   \n",
      "1  രാസവളങ്ങൾ എന്തൊക്കെയാണ്?   \n",
      "2   എന്താണ് കീട നിയന്ത്രണം?   \n",
      "3     What is pest control?   \n",
      "\n",
      "                                              Answer Source Language  \\\n",
      "0  Fertilizers are substances that are added to s...              en   \n",
      "1  വിളകളുടെ വളർച്ചയും ഗുണനിലവാരവും മെച്ചപ്പെടുത്ത...              ml   \n",
      "2  ഒരു ജീവനക്കാരുടെ നിയന്ത്രണം അല്ലെങ്കിൽ മാനേജ്മ...              ml   \n",
      "3  is the regulation or management of a species d...              en   \n",
      "\n",
      "  Question Language            Timestamp  \n",
      "0                en  2024-11-30 19:15:54  \n",
      "1                ml  2024-11-30 19:16:10  \n",
      "2                ml  2024-11-30 19:17:17  \n",
      "3                en  2024-11-30 19:18:47  \n",
      "\n",
      "Necessary Columns Check:\n",
      "Question: Present\n",
      "Answer: Present\n",
      "Detected Language: Absent\n",
      "Actual Language: Absent\n",
      "Relevance Score: Absent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_check_csv(csv_file_path):\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Print general information about the dataframe\n",
    "        print(\"DataFrame Info:\")\n",
    "        df.info()\n",
    "\n",
    "        # Display the first few rows of the dataframe\n",
    "        print(\"\\nFirst 5 Rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Check the availability of essential columns\n",
    "        necessary_columns = ['Question', 'Answer', 'Detected Language', 'Actual Language', 'Relevance Score']\n",
    "        existing_columns = df.columns.tolist()\n",
    "        print(\"\\nNecessary Columns Check:\")\n",
    "        for column in necessary_columns:\n",
    "            print(f\"{column}: {'Present' if column in existing_columns else 'Absent'}\")\n",
    "        \n",
    "        # Summarize the availability of data for key metrics\n",
    "        if 'Actual Language' in df.columns and 'Detected Language' in df.columns:\n",
    "            print(\"\\nEntries with Actual Language Labels:\", df['Actual Language'].notnull().sum())\n",
    "        if 'Relevance Score' in df.columns:\n",
    "            print(\"Entries with Relevance Scores:\", df['Relevance Score'].notnull().sum())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Assuming the path to your CSV\n",
    "csv_file_path = 'D:/YEAR 4/SEM 7/NLP/LAB/PROJECT/codes/conversation_logs.csv'\n",
    "load_and_check_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47ba6c7-b965-44ae-b431-29b9a716b38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Language data or Detected Language data is not available.\n",
      "Unable to calculate language detection accuracy due to missing data.\n",
      "Relevance scores are not logged.\n",
      "Unable to calculate answer relevance due to missing data.\n",
      "Insufficient data to generate a classification report.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_interaction_logs(log_path):\n",
    "    \"\"\"\n",
    "    Load the chatbot interaction logs from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(log_path)\n",
    "\n",
    "def calculate_language_accuracy(log_df):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the language detection.\n",
    "    Assumes that 'Detected Language' and 'Actual Language' columns are correctly logged.\n",
    "    \"\"\"\n",
    "    if 'Actual Language' in log_df.columns and 'Detected Language' in log_df.columns:\n",
    "        accuracy = accuracy_score(log_df['Actual Language'], log_df['Detected Language'])\n",
    "        return accuracy\n",
    "    else:\n",
    "        print(\"Actual Language data or Detected Language data is not available.\")\n",
    "        return None\n",
    "\n",
    "def answer_relevance_metrics(log_df):\n",
    "    \"\"\"\n",
    "    Calculate metrics related to the relevance of answers.\n",
    "    Assumes that a 'Relevance Score' column is present and properly logged.\n",
    "    \"\"\"\n",
    "    if 'Relevance Score' in log_df.columns:\n",
    "        average_relevance = log_df['Relevance Score'].mean()\n",
    "        return average_relevance\n",
    "    else:\n",
    "        print(\"Relevance scores are not logged.\")\n",
    "        return None\n",
    "\n",
    "def print_classification_report(log_df):\n",
    "    \"\"\"\n",
    "    Print the classification report for language detection.\n",
    "    Assumes that 'Actual Language' and 'Detected Language' columns are correctly logged.\n",
    "    \"\"\"\n",
    "    if 'Actual Language' in log_df.columns and 'Detected Language' in log_df.columns:\n",
    "        report = classification_report(log_df['Actual Language'], log_df['Detected Language'])\n",
    "        print(report)\n",
    "    else:\n",
    "        print(\"Insufficient data to generate a classification report.\")\n",
    "\n",
    "def main():\n",
    "    log_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\conversation_logs.csv'\n",
    "    log_df = load_interaction_logs(log_path)\n",
    "    \n",
    "    # Calculate and print language detection accuracy\n",
    "    lang_accuracy = calculate_language_accuracy(log_df)\n",
    "    if lang_accuracy is not None:\n",
    "        print(f\"Language Detection Accuracy: {lang_accuracy:.2f}\")\n",
    "    else:\n",
    "        print(\"Unable to calculate language detection accuracy due to missing data.\")\n",
    "    \n",
    "    # Calculate and print answer relevance metrics\n",
    "    relevance = answer_relevance_metrics(log_df)\n",
    "    if relevance is not None:\n",
    "        print(f\"Average Relevance Score: {relevance:.2f}\")\n",
    "    else:\n",
    "        print(\"Unable to calculate answer relevance due to missing data.\")\n",
    "    \n",
    "    # Print classification report for language detection\n",
    "    print_classification_report(log_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd12f45-3b64-4d9c-8865-f64534566603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detection Accuracy: 1.00\n",
      "Average Answer Relevance Score: 5.00\n",
      "Error Rate: 0.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       1.00      1.00      1.00        12\n",
      "          ml       1.00      1.00      1.00         6\n",
      "          te       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_data(csv_file_path):\n",
    "    \"\"\"Load the chatbot interaction logs from a CSV file.\"\"\"\n",
    "    return pd.read_csv(csv_file_path)\n",
    "\n",
    "def calculate_language_accuracy(log_df):\n",
    "    \"\"\"Calculate the accuracy of language detection.\"\"\"\n",
    "    if 'Actual Language' in log_df.columns and 'Detected Language' in log_df.columns:\n",
    "        return accuracy_score(log_df['Actual Language'], log_df['Detected Language'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def evaluate_answer_quality(log_df):\n",
    "    \"\"\"Evaluate the average relevance score of the answers provided by the chatbot.\"\"\"\n",
    "    if 'Relevance Score' in log_df.columns:\n",
    "        return log_df['Relevance Score'].mean()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_error_rate(log_df):\n",
    "    \"\"\"Calculate the error rate based on correct outputs logged.\"\"\"\n",
    "    if 'Correct Output' in log_df.columns:\n",
    "        return 1 - (log_df['Correct Output'].astype(bool).mean())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def print_detailed_report(log_df):\n",
    "    \"\"\"Print a detailed classification report for language detection.\"\"\"\n",
    "    if 'Actual Language' in log_df.columns and 'Detected Language' in log_df.columns:\n",
    "        print(classification_report(log_df['Actual Language'], log_df['Detected Language']))\n",
    "\n",
    "def main():\n",
    "    csv_file_path = r'D:\\YEAR 4\\SEM 7\\NLP\\LAB\\PROJECT\\codes\\conversation_logs.csv'\n",
    "    log_df = load_data(csv_file_path)\n",
    "    \n",
    "    language_accuracy = calculate_language_accuracy(log_df)\n",
    "    answer_quality = evaluate_answer_quality(log_df)\n",
    "    error_rate = calculate_error_rate(log_df)\n",
    "\n",
    "    print(f\"Language Detection Accuracy: {language_accuracy:.2f}\" if language_accuracy is not None else \"Language detection data unavailable.\")\n",
    "    print(f\"Average Answer Relevance Score: {answer_quality:.2f}\" if answer_quality is not None else \"Answer relevance scores unavailable.\")\n",
    "    print(f\"Error Rate: {error_rate:.2f}\" if error_rate is not None else \"Error data unavailable.\")\n",
    "    \n",
    "    print_detailed_report(log_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969dcb7-0d20-41cd-aa8a-a826e7c18b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
